# Chest X-Ray Disease Detection with AWS SageMaker

A production-ready machine learning system for detecting diseases in chest X-ray images, built using AWS SageMaker with complete MLOps practices including automated training, serverless deployment, monitoring, and CI/CD.

## ğŸ¯ Project Overview

This project demonstrates end-to-end machine learning engineering on AWS, from data preparation through production deployment. It implements a deep learning model for multi-label classification of 14 disease categories from chest X-ray images.

### Key Features

âœ… **Production MLOps Pipeline** - Complete workflow from training to deployment  
âœ… **Serverless Architecture** - Pay-per-use inference with auto-scaling  
âœ… **Sub-300ms Latency** - Real-time predictions with 271ms average response time  
âœ… **Cost Optimized** - $0.20 per 1,000 predictions with serverless deployment  
âœ… **Interactive Web UI** - FastAPI-powered interface with drag-and-drop upload  
âœ… **Comprehensive Monitoring** - Prometheus metrics and CloudWatch integration  
âœ… **CI/CD Pipeline** - Automated testing and deployment with GitHub Actions  
âœ… **Healthcare Compliant** - HIPAA-aware architecture with encryption and audit logging  

## ğŸ“Š Performance Metrics

| Metric | Value |
|--------|-------|
| Average Inference Latency | **271ms** |
| P95 Latency | **456ms** |
| Success Rate | **100%** |
| Cost per 1K Predictions | **$0.20** |
| Disease Categories | **14** |
| Model Architecture | **DenseNet121** |

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Data Pipeline  â”‚â”€â”€â”€â”€â–¶â”‚  Training (GPU)  â”‚â”€â”€â”€â”€â–¶â”‚  Model Registry â”‚
â”‚   (S3 + ETL)    â”‚     â”‚  ml.g4dn.xlarge  â”‚     â”‚   (Versioning)  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                                           â”‚
                                                           â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Monitoring    â”‚â—€â”€â”€â”€â”€â”‚   Serverless     â”‚â—€â”€â”€â”€â”€â”‚   FastAPI UI    â”‚
â”‚  (Prometheus)   â”‚     â”‚   Endpoint       â”‚     â”‚  (Web Interface)â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸš€ Quick Start

### Prerequisites

- AWS Account with SageMaker access
- Python 3.9+
- AWS CLI configured
- ~$10 budget for experimentation

### Installation

```bash
# Clone the repository
git clone https://github.com/LANGANM52/chest-xray-sagemaker.git
cd chest-xray-sagemaker

# Create virtual environment
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate

# Install dependencies
pip install -r requirements.txt

# Configure AWS credentials
aws configure
```

### Setup AWS Resources

```bash
# 1. Create IAM role for SageMaker
aws iam create-role --role-name SageMakerExecutionRole \
  --assume-role-policy-document file://trust-policy.json

aws iam attach-role-policy --role-name SageMakerExecutionRole \
  --policy-arn arn:aws:iam::aws:policy/AmazonSageMakerFullAccess

aws iam attach-role-policy --role-name SageMakerExecutionRole \
  --policy-arn arn:aws:iam::aws:policy/AmazonS3FullAccess

# 2. Create S3 bucket
aws s3 mb s3://your-bucket-name --region us-east-1

# 3. Update .env file with your details
```

### Train Model

```bash
# Prepare dataset
python src/training/prepare_data.py --s3-bucket your-bucket-name

# Launch training job
python src/training/train_sagemaker.py \
  --instance-type ml.g4dn.xlarge \
  --bucket your-bucket-name \
  --role arn:aws:iam::YOUR-ACCOUNT:role/SageMakerExecutionRole
```

**Training Time:** ~5-10 minutes (with sample data)  
**Cost:** ~$1-2

### Deploy Model

```bash
# Deploy to serverless endpoint
python src/inference/deploy.py \
  --deployment-type serverless \
  --memory-size 2048 \
  --bucket your-bucket-name \
  --role arn:aws:iam::YOUR-ACCOUNT:role/SageMakerExecutionRole
```

**Deployment Time:** ~5-10 minutes  
**Cost:** Pay per request (no idle costs!)

### Test Endpoint

```bash
# Single prediction
python src/inference/test_endpoint.py --endpoint-name YOUR-ENDPOINT-NAME

# Load test
python src/inference/test_endpoint.py \
  --endpoint-name YOUR-ENDPOINT-NAME \
  --load-test \
  --num-requests 10
```

### Run Web Interface

```bash
# Start FastAPI server
uvicorn app:app --reload

# Open browser to http://localhost:8000
```

## ğŸ“ Project Structure

```
chest-xray-classifier/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ training/
â”‚   â”‚   â”œâ”€â”€ prepare_data.py      # Data preparation pipeline
â”‚   â”‚   â”œâ”€â”€ train.py              # PyTorch training script
â”‚   â”‚   â””â”€â”€ train_sagemaker.py    # SageMaker orchestration
â”‚   â”œâ”€â”€ inference/
â”‚   â”‚   â”œâ”€â”€ inference.py          # Model inference handler
â”‚   â”‚   â”œâ”€â”€ deploy.py             # Deployment script
â”‚   â”‚   â””â”€â”€ test_endpoint.py      # Testing utilities
â”‚   â”œâ”€â”€ monitoring/
â”‚   â”‚   â””â”€â”€ metrics.py            # Prometheus metrics
â”‚   â””â”€â”€ config.py                 # Configuration management
â”œâ”€â”€ tests/
â”‚   â””â”€â”€ test_training.py          # Unit tests
â”œâ”€â”€ docs/
â”‚   â”œâ”€â”€ architecture.md           # Architecture details
â”‚   â”œâ”€â”€ cost_analysis.md          # Cost breakdown
â”‚   â””â”€â”€ quickstart.md             # Setup guide
â”œâ”€â”€ .github/
â”‚   â””â”€â”€ workflows/
â”‚       â””â”€â”€ ci-cd.yml             # CI/CD pipeline
â”œâ”€â”€ app.py                        # FastAPI web interface
â”œâ”€â”€ requirements.txt              # Python dependencies
â”œâ”€â”€ .env.example                  # Environment template
â””â”€â”€ README.md                     # This file
```

## ğŸ› ï¸ Technology Stack

**Machine Learning:**
- PyTorch 2.0
- DenseNet121 (pre-trained on ImageNet)
- Multi-label classification

**AWS Services:**
- SageMaker (Training, Inference, Experiments)
- S3 (data and model storage)
- IAM (security and permissions)
- CloudWatch (logging and monitoring)

**Backend & API:**
- FastAPI (web framework)
- Uvicorn (ASGI server)
- Pydantic (data validation)

**Monitoring & Observability:**
- Prometheus (metrics)
- CloudWatch (AWS metrics)
- Structured JSON logging

**DevOps & Infrastructure:**
- GitHub Actions (CI/CD)
- Docker (containerization)
- pytest (testing)

## ğŸ“ˆ Model Details

**Architecture:** DenseNet121 with custom classifier head

**Input:** 224x224 RGB chest X-ray images

**Output:** 14 probability scores (0-1) for:
- Atelectasis
- Cardiomegaly
- Effusion
- Infiltration
- Mass
- Nodule
- Pneumonia
- Pneumothorax
- Consolidation
- Edema
- Emphysema
- Fibrosis
- Pleural Thickening
- Hernia

**Dataset:** NIH Chest X-Ray Dataset (designed for 112K+ images)

## ğŸ’° Cost Analysis

### Development Costs

| Item | Cost |
|------|------|
| Training (ml.g4dn.xlarge, ~10 min) | $1-2 |
| Serverless Inference (1000 requests) | $0.20 |
| S3 Storage (50GB) | $1.15/month |
| CloudWatch Logs | $2-3/month |
| **Total Development** | **~$5-10** |

### Production Costs

**Serverless Inference:**
- $0.20 per 1M inference milliseconds
- No idle costs - only pay for actual usage
- Example: 1,000 predictions @ 271ms each = $0.20

**Cost Optimization Strategies:**
- Serverless deployment (no idle costs)
- S3 lifecycle policies (automatic archival)
- CloudWatch log retention policies
- Right-sized memory allocation (2048 MB)

## ğŸ”’ Security & Compliance

**Data Security:**
- Encryption at rest (S3 server-side encryption)
- Encryption in transit (TLS 1.2+)
- IAM roles with least privilege

**Healthcare Compliance:**
- HIPAA-aware architecture design
- Audit logging with CloudTrail
- VPC isolation capabilities
- No PHI in logs or metrics

**Note:** This is a demonstration project. For actual medical use, additional compliance certifications and testing would be required.

## ğŸ§ª Testing

```bash
# Run unit tests
pytest tests/

# Run integration tests
pytest tests/integration/

# Code quality checks
black src/ tests/
flake8 src/ tests/
mypy src/
```

## ğŸ“Š Monitoring

**Prometheus Metrics:**
- Prediction count and success rate
- Latency distribution (P50, P95, P99)
- Error rates by type
- Confidence score distribution

**CloudWatch Metrics:**
- Endpoint invocations
- Model latency
- Memory utilization
- Throttling events

**Access Metrics:**
```bash
# Start Prometheus server
python src/monitoring/metrics.py

# View metrics at http://localhost:9090/metrics
```

## ğŸš§ Clean Up

**Important:** Delete resources to avoid charges!

```bash
# Delete endpoint
python src/inference/deploy.py --delete-endpoint YOUR-ENDPOINT-NAME

# Or via AWS CLI
aws sagemaker delete-endpoint --endpoint-name YOUR-ENDPOINT-NAME
aws sagemaker delete-endpoint-config --endpoint-config-name YOUR-ENDPOINT-NAME
aws sagemaker delete-model --model-name YOUR-MODEL-NAME
```

## ğŸ“š Documentation

- [Architecture Deep Dive](docs/architecture.md)
- [Cost Analysis](docs/cost_analysis.md)
- [Quick Start Guide](docs/quickstart.md)

## ğŸ¯ Future Enhancements

- [ ] Model explainability (Grad-CAM visualizations)
- [ ] A/B testing framework for model versions
- [ ] Real-time model monitoring and drift detection
- [ ] Mobile application integration
- [ ] Multi-model ensemble predictions
- [ ] Automated model retraining pipeline
- [ ] Extended dataset support

## ğŸ¤ Contributing

This is a portfolio project, but suggestions and improvements are welcome! Feel free to open an issue or submit a pull request.
